{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from tools.data_loading import load_images, load_labels, dummy_code, load_images_resized\n",
    "from tools.feature_learning import pins_generation\n",
    "from tools.hog import hog\n",
    "from tools.kernels import kernel_matrix\n",
    "from tools.optimization import find_f\n",
    "from tools.prediction import pred\n",
    "from tools.process_images import process_images\n",
    "from tools.quantization import kmeans\n",
    "from tools.submission import labels_to_csv\n",
    "from tools.visualization import imshow, dump_as_png, reshape_as_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = load_images_resized(type=\"train\")\n",
    "n_train = X_train.shape[0]\n",
    "Y_labels_train = load_labels()\n",
    "Y_train = dummy_code(Y_labels_train)\n",
    "n_classes = Y_train.shape[1]\n",
    "X_train = X_train - X_train.min(axis=0)\n",
    "X_train = X_train / X_train.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train2 = np.zeros((5000,63,63,3))\n",
    "for i in range(3):\n",
    "    X_train2[:,:,:,i] = X_train\n",
    "image_list = X_train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filter_sigma=0.1\n",
    "filter_shape=5\n",
    "hog_cell_size=8\n",
    "disc_grid=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_images = image_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1fe1c2b3254dfb944baba5d142d27c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hog_list = []\n",
    "for i in tqdm_notebook(range(n_images), desc=\"Images\"):\n",
    "    image = image_list[i,:,:,:]\n",
    "    hog_list.append(\n",
    "        hog(\n",
    "            image,\n",
    "            filter_sigma=filter_sigma,\n",
    "            filter_shape=filter_shape,\n",
    "            hog_cell_size=hog_cell_size,\n",
    "            disc_grid=disc_grid,\n",
    "            normalize=True,\n",
    "            block_size=4))\n",
    "    \n",
    "n_features = hog_list[0].size\n",
    "X_hog = np.array(hog_list).reshape((n_images, n_features)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "indices = np.random.permutation(X_hog.shape[0])\n",
    "training_idx, test_idx = indices[:int(0.9*n_train)], indices[int(0.9*n_train):]\n",
    "\n",
    "X_sample = X_hog[training_idx, :]\n",
    "n_sample = X_sample.shape[0]\n",
    "Y_sample = Y_train[training_idx,:]\n",
    "Y_labels_sample = Y_labels_train[training_idx]\n",
    "\n",
    "X_test = X_hog[test_idx, :]\n",
    "n_test = X_test.shape[0]\n",
    "Y_labels_test = Y_labels_train[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pre-computing distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_dist = squareform(pdist(X_sample, \"euclidean\"))\n",
    "train_test_dist = cdist(X_sample[:500], X_sample, \"euclidean\")\n",
    "test_dist = cdist(X_test, X_sample, \"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pre-computing inner products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_inner = X_sample.dot(X_sample.T)\n",
    "train_test_inner = X_sample[:500].dot(X_sample.T)\n",
    "test_inner = X_test.dot(X_sample.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kernel_type = \"polynomial\"\n",
    "classifier_type = \"fast_svm\"\n",
    "degree = 4\n",
    "constant = 5\n",
    "lamb = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kernel_type=\"rbf\"\n",
    "sigma = 15.5\n",
    "lamb = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kernel choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K_sample = kernel_matrix(\n",
    "    X_sample,\n",
    "    kernel_type=kernel_type,\n",
    "    degree=degree,\n",
    "    constant=constant,\n",
    "    sigma=sigma,\n",
    "    dist=train_dist,\n",
    "    inner=train_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 4500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classifier choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d23c9cd09804d25b69ac5ea466dd9ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = np.zeros((n_classes, n_sample))\n",
    "for dig in tqdm_notebook(range(n_classes), desc=\"Classes\"):\n",
    "    alpha[dig, :] = find_f(K_sample, Y_sample[:, dig],\n",
    "                           prob_type=classifier_type, lamb=lamb, n_iter=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on the train set is of 0.974\n"
     ]
    }
   ],
   "source": [
    "Y_pred_train = pred(\n",
    "    X_sample, X_sample[:500], alpha,\n",
    "    kernel_type=kernel_type,\n",
    "    degree=degree,\n",
    "    constant=constant,\n",
    "    sigma=sigma,\n",
    "    dist=train_test_dist,\n",
    "    inner=train_test_inner)\n",
    "\n",
    "\n",
    "Y_labels_pred_train = np.argmax(Y_pred_train, axis=1)\n",
    "prec = np.mean(Y_labels_pred_train == Y_labels_sample[:500])\n",
    "print(\"The precision on the train set is of {}\".format(prec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on the test set is of 0.412\n"
     ]
    }
   ],
   "source": [
    "Y_pred = pred(\n",
    "    X_sample, X_test, alpha,\n",
    "    kernel_type=kernel_type,\n",
    "    degree=degree,\n",
    "    constant=constant,\n",
    "    sigma=sigma,\n",
    "    dist=test_dist,\n",
    "    inner=test_inner)\n",
    "\n",
    "\n",
    "Y_labels_pred = np.argmax(Y_pred, axis=1)\n",
    "prec = np.mean(Y_labels_pred == Y_labels_test)\n",
    "print(\"The precision on the test set is of {}\".format(prec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Grid search from hell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coordinate_ascent(out_q, dig, **kwargs):\n",
    "    out_q.put(\n",
    "        [\n",
    "            dig,\n",
    "            find_f(**kwargs)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### For polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kernel_type = \"polynomial\"\n",
    "degrees = [4, 5, 6]\n",
    "n_degrees = len(degrees)\n",
    "constants = [1, 5, 50, 100]\n",
    "n_constants = len(constants)\n",
    "lambs = [1e-9, 1e-5, 0.1, 1]\n",
    "n_lambs = len(lambs)\n",
    "train_prec = np.zeros((n_degrees, n_constants, n_lambs))\n",
    "test_prec = np.zeros((n_degrees, n_constants, n_lambs))\n",
    "for d in tqdm_notebook(range(n_degrees), desc=\"Degrees\"):\n",
    "    for c in tqdm_notebook(range(n_constants), desc=\"Constants\"):\n",
    "        # Kernel matrix computation\n",
    "        K_sample = kernel_matrix(\n",
    "            X_sample, kernel_type=kernel_type, degree=degrees[d], constant=constants[c], inner=train_inner)\n",
    "        for l in tqdm_notebook(range(n_lambs), desc=\"Lambdas\"):\n",
    "            # Coordinate ascent with multiprocessing\n",
    "            alpha = np.zeros((n_classes, n_sample))\n",
    "            out_q = Queue()\n",
    "            procs = list()\n",
    "            for dig in range(n_classes):\n",
    "                p = Process(\n",
    "                    target=coordinate_ascent,\n",
    "                    args=(out_q, dig),\n",
    "                    kwargs={\n",
    "                        \"K\":K_sample, \"Y\":Y_sample[:, dig], \"prob_type\":classifier_type, \"lamb\":lambs[l], \"n_iter\":40000\n",
    "                    }\n",
    "                )\n",
    "                procs.append(p)\n",
    "                p.start()\n",
    "            for i in range(n_classes):\n",
    "                res = out_q.get()\n",
    "                alpha[res[0], :] = res[1]\n",
    "\n",
    "            for p in procs:\n",
    "                p.join()\n",
    "            # Precision on train set\n",
    "            Y_pred_train = pred(\n",
    "                X_sample, X_sample[:500], alpha,\n",
    "                kernel_type=kernel_type,\n",
    "                degree=degrees[d],\n",
    "                constant=constants[c],\n",
    "                inner=train_test_inner)\n",
    "\n",
    "            Y_labels_pred_train = np.argmax(Y_pred_train, axis=1)\n",
    "            train_prec[d, c, l] = np.mean(Y_labels_pred_train == Y_labels_sample[:500])\n",
    "            # Precision on test set\n",
    "            Y_pred= pred(\n",
    "                X_sample, X_test, alpha,\n",
    "                kernel_type=kernel_type,\n",
    "                degree=degrees[d],\n",
    "                constant=constants[c],\n",
    "                inner=test_inner)\n",
    "\n",
    "            Y_labels_pred = np.argmax(Y_pred, axis=1)\n",
    "            test_prec[d, c, l] = np.mean(Y_labels_pred == Y_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### For RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7865b558a4430cbdd4d3dc9720012a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7f02d770204fc4ab21378f2f39e7e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094091bf5ef548e09b068923e5689991"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c6575282df4a30b3c8b1d945b5c661"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a375dbc3d0384461ba2a2da9af48165d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1012c172d994612acbaa758ef2fa5ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f064ea76e62403f8eb819aaddce27ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b3f501473948049d502fb4b32a6cee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kernel_type=\"rbf\"\n",
    "sigmas = [8, 9, 9.5, 10, 10.5, 11, 12]\n",
    "n_sigmas = len(sigmas)\n",
    "lambs = [1e-6, 5*1e-6, 1e-5]\n",
    "n_lambs = len(lambs)\n",
    "train_prec_rbf = np.zeros((n_sigmas, n_lambs))\n",
    "test_prec_rbf = np.zeros((n_sigmas, n_lambs))\n",
    "for s in tqdm_notebook(range(n_sigmas), desc=\"Sigmas\"):\n",
    "    # Kernel matrix computation\n",
    "    K_sample = kernel_matrix(X_sample, kernel_type=kernel_type, sigma=sigmas[s], dist=train_dist)\n",
    "    for l in tqdm_notebook(range(n_lambs), desc=\"Lambdas\"):\n",
    "        # Coordinate ascent with multiprocessing\n",
    "        alpha = np.zeros((n_classes, n_sample))\n",
    "        out_q = Queue()\n",
    "        procs = list()\n",
    "        for dig in range(n_classes):\n",
    "            p = Process(\n",
    "                target=coordinate_ascent,\n",
    "                args=(out_q, dig),\n",
    "                kwargs={\n",
    "                    \"K\":K_sample, \"Y\":Y_sample[:, dig], \"prob_type\":classifier_type, \"lamb\":lambs[l], \"n_iter\":40000\n",
    "                }\n",
    "            )\n",
    "            procs.append(p)\n",
    "            p.start()\n",
    "        for i in range(n_classes):\n",
    "            res = out_q.get()\n",
    "            alpha[res[0], :] = res[1]\n",
    "\n",
    "        for p in procs:\n",
    "            p.join()\n",
    "        # Precision on train set\n",
    "        Y_pred_train= pred(X_sample, X_sample[:500], alpha,\n",
    "                              kernel_type=kernel_type, sigma=sigmas[s], dist=train_test_dist)\n",
    "        Y_labels_pred_train = np.argmax(Y_pred_train, axis=1)\n",
    "        train_prec_rbf[s, l] = np.mean(Y_labels_pred_train == Y_labels_sample[:500])\n",
    "        # Precision on test set\n",
    "        Y_pred = pred(X_sample, X_test, alpha,\n",
    "                              kernel_type=kernel_type, sigma=sigmas[s], dist=test_dist)\n",
    "\n",
    "\n",
    "        Y_labels_pred = np.argmax(Y_pred, axis=1)\n",
    "        test_prec_rbf[s, l] = np.mean(Y_labels_pred == Y_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52 ,  0.526,  0.522],\n",
       "       [ 0.542,  0.536,  0.534],\n",
       "       [ 0.532,  0.532,  0.534],\n",
       "       [ 0.536,  0.538,  0.538],\n",
       "       [ 0.532,  0.534,  0.532],\n",
       "       [ 0.532,  0.534,  0.528],\n",
       "       [ 0.524,  0.514,  0.514]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prec_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prec_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_eval = load_images_resized(type=\"test\")\n",
    "X_eval = X_eval - X_eval.min(axis=0)\n",
    "X_eval = X_eval / X_eval.max(axis=0)\n",
    "n_eval = X_eval.shape[0]\n",
    "X_eval2 = np.zeros((2000,63,63,3))\n",
    "for i in range(3):\n",
    "    X_eval2[:,:,:,i] = X_eval\n",
    "image_list_eval = X_eval2\n",
    "\n",
    "# Visual features for submission\n",
    "hog_list_eval = []\n",
    "for i in tqdm_notebook(range(n_eval), desc=\"Submission images\"):\n",
    "    image = image_list_eval[i,:,:,:]\n",
    "    hog_list_eval.append(\n",
    "        hog(\n",
    "            image,\n",
    "            filter_sigma=filter_sigma,\n",
    "            filter_shape=filter_shape,\n",
    "            hog_cell_size=hog_cell_size,\n",
    "            disc_grid=disc_grid))\n",
    "    \n",
    "n_features = hog_list_eval[0].size\n",
    "X_hog_eval = np.array(hog_list_eval).reshape((n_eval, n_features)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_eval = pred(X_sample, X_hog_eval, alpha,\n",
    "                      kernel_type=kernel_type, degree=degree, constant=constant, sigma=sigma)\n",
    "\n",
    "\n",
    "Y_labels_eval = np.argmax(Y_eval, axis=1)\n",
    "\n",
    "\n",
    "# Submission\n",
    "labels_to_csv(Y_labels_eval, kernel=kernel_type, algo=\"svm_hog\",user=\"Zac_big_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
