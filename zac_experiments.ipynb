{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tools.corner_response_function import compute_gaussian_grad,compute_corner_response\n",
    "from tools.visualization import reshape_as_images, imshow\n",
    "from tools.data_loading import load_images\n",
    "from tools.discretization import discretize_orientation, pin_as_vect\n",
    "from tools.quantization import kmeans, vf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filter_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = load_images(type=\"train\")\n",
    "X = reshape_as_images(X) # 5000 x 32 x 32 x 3\n",
    "images = X.mean(axis=3) # 5000 x 32 x 32\n",
    "window_size = 5\n",
    "stride = 3\n",
    "patch_size = 5\n",
    "pins = list()\n",
    "\n",
    "R_size = (images.shape[1] - window_size - filter_size)//stride + 1\n",
    "R = np.zeros((images.shape[0], R_size, R_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for image_idx in range(images.shape[0]):\n",
    "        image_mat = images[image_idx]\n",
    "        im_size = image_mat.shape[0]  # normally 32\n",
    "        image_grad_x, image_grad_y = compute_gaussian_grad(image_mat)\n",
    "\n",
    "        for i in range(R_size):\n",
    "            for j in range(R_size):\n",
    "                I_x = image_grad_x[i*stride:i*stride+window_size,\n",
    "                                   j*stride:j*stride+window_size]\n",
    "                I_y = image_grad_y[i*stride:i*stride+window_size,\n",
    "                                   j*stride:j*stride+window_size]\n",
    "\n",
    "                R[image_idx, i, j] = compute_corner_response(I_x, I_y)\n",
    "        # thresholding of R\n",
    "        R[image_idx] = np.abs(R[image_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def from_R_to_im(x, y, window_size, stride):\n",
    "    x = x * stride + (window_size - 1)//2 + (filter_size - 1)//2\n",
    "    y = y * stride + (window_size - 1)//2 + (filter_size - 1)//2\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "def R_to_heatmap(R, window_size, stride, im_size):\n",
    "    R_size = R.shape[0]\n",
    "    # create heatmap\n",
    "    heatmap = np.zeros((im_size, im_size))\n",
    "    for i in range(R_size):\n",
    "        for j in range(R_size):\n",
    "            ix, iy = from_R_to_im(i, j, window_size, stride)\n",
    "            heatmap[ix:ix+window_size,\n",
    "                    iy:iy+window_size] = R[i, j]\n",
    "    heatmap /= heatmap.max()\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i, j = np.where(R[ind] > np.percentile(R[ind], 75))\n",
    "i, j = from_R_to_im(i, j, window_size, stride)\n",
    "\n",
    "x, y = j, i\n",
    "\n",
    "heatmap = R_to_heatmap(R[ind], window_size, stride, im_size)\n",
    "imshow(images[ind], points_of_interest=(x, y), heatmap=heatmap)\n",
    "ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pins_img_ids = []\n",
    "pins_coords = []\n",
    "im_to_pins = dict.fromkeys(range(images.shape[0]), [])\n",
    "for image_idx in range(images.shape[0]):\n",
    "    i_s, j_s = np.where(\n",
    "        R[image_idx] > np.percentile(R[image_idx], 75))\n",
    "    i_s, j_s = from_R_to_im(i_s, j_s, window_size, stride)\n",
    "    for i, j in zip(i_s, j_s):  # i, j are the coordinates in R of POI\n",
    "        patch_x = image_grad_x[i-patch_size//2:i+patch_size//2+1,\n",
    "                               j-patch_size//2:j+patch_size//2+1]\n",
    "        patch_y = image_grad_y[i-patch_size//2:i+patch_size//2+1,\n",
    "                               j-patch_size//2:j+patch_size//2+1]\n",
    "        pin_as_matrix = discretize_orientation(patch_x, patch_y)\n",
    "        pin = pin_as_vect(pin_as_matrix)\n",
    "        pins.append(pin) # pins is list of all pins for all images\n",
    "        # for visualization purposes\n",
    "        pins_img_ids.append(image_idx)\n",
    "        pins_coords.append((i,j))\n",
    "        im_to_pins[image_idx].append(pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sep_indices = np.random.permutation(X.shape[0])\n",
    "training_idx, test_idx = sep_indices[:int(0.9*n_train)], sep_indices[int(0.9*n_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_pins = list() #  list of all pins for training images\n",
    "for idx in training_idx:\n",
    "    train_pins += im_to_pins[idx]\n",
    "pins_mat = np.vstack(train_pins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visual_features = kmeans(pins_mat, 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vf_vector(train_pins, visual_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = np.argmin(np.linalg.norm(pins_mat[:, None, :] - visual_features, axis=2), axis=1)\n",
    "\n",
    "\n",
    "nb_features = 3\n",
    "for i in range(nb_features): # first three visual features\n",
    "    indices = np.where(y == i)[0][:9]\n",
    "    f, axarr = plt.subplots(3, 3)\n",
    "    \n",
    "    for aa in range(9):\n",
    "        r = aa // 3\n",
    "        s = aa - r * 3\n",
    "        ii, jj = pins_coords[indices[aa]]\n",
    "        image = X_sample[pins_img_ids[indices[aa]]][ii-patch_size//2:ii+patch_size//2+1,\n",
    "                               jj-patch_size//2:jj+patch_size//2+1]\n",
    "        image -= X_sample[pins_img_ids].min()\n",
    "        image /= X_sample[pins_img_ids].max()\n",
    "        axarr[r,s].imshow(image, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Actual pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_labels_train = load_labels()\n",
    "Y_train = dummy_code(Y_labels_train)\n",
    "n_classes = Y_train.shape[1]\n",
    "\n",
    "X_proc = process_images(X, proc_type=\"bovf\", centroids=centroids, im_to_pins=im_to_pins)\n",
    "n_train, n_var = X_proc.shape\n",
    "X_sample = X_proc[training_idx, :]\n",
    "n_sample = X_sample.shape[0]\n",
    "X_test = X_proc[test_idx, :]\n",
    "n_test = X_test.shape[0]\n",
    "Y_sample = Y_train[training_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "kernel_type = \"linear\"\n",
    "K_sample = kernel_matrix(X_sample, kernel_type=kernel_type)\n",
    "\n",
    "classifier_type = \"linear regression\"\n",
    "alpha = np.zeros((n_classes, n_sample))\n",
    "for dig in range(n_classes):\n",
    "    alpha[dig, :] = find_f(K_sample, Y_sample[:, dig],\n",
    "                           prob_type=classifier_type, lamb=1.0)\n",
    "\n",
    "# Evaluation\n",
    "Y_pred = np.zeros((X_test.shape[0], n_classes))\n",
    "for dig in range(n_classes):\n",
    "    Y_pred[:, dig] = pred(X_sample, X_test, alpha[dig, :],\n",
    "                          kernel_type=kernel_type)\n",
    "\n",
    "\n",
    "Y_labels_pred = np.argmax(Y_pred, axis=1)\n",
    "prec = np.mean(Y_labels_pred == Y_labels_train[test_idx])\n",
    "print(prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
